# Stream Transcriber

Un proyecto para transcribir v铆deos de YouTube a texto en tiempo real, admitiendo tanto streams en vivo como v铆deos ya subidos a la plataforma.

## Descripci贸n

Stream Transcriber es una herramienta que permite capturar streams de YouTube y transcribir su contenido de audio a texto de forma autom谩tica mientras el stream est谩 en vivo. Este proyecto soporta dos modelos de transcripci贸n:

1. **Whisper**: Procesa los datos en memoria RAM y es adecuado para transcripciones r谩pidas.
2. **WhisperX**: Utiliza archivos temporales y ofrece detecci贸n de hablantes. **(En desarrollo)**


## Caracter铆sticas 

- Captura de streams de YouTube en vivo
- Transcripci贸n autom谩tica de audio a texto
- Procesamiento en tiempo real
- Guardado de transcripciones para consulta posterior
- Soporte para modelos Whisper y WhisperX
- Posibilidad de diarizaci贸n de hablantes (WhisperX)

## Requisitos

- Python 3.8 o superior (hasta 3.12 para compatibilidad con WhisperX)
- FFmpeg instalado en el sistema
- Conexi贸n a internet

## Dependencias

Se encontrar谩n las siguientes dependencias en el archivo `requirements.txt`:

```plaintext
yt-dlp
openai-whisper
ffmpeg-python
whisperx
```

## Instalaci贸n

1. Clona este repositorio
   ```bash
   git clone https://github.com/your-username/Stream-transcriber.git
   cd Stream-transcriber
   ```

2. Instala las dependencias requeridas
   ```bash
   pip install -r requirements.txt
   ```

3. Aseg煤rate de tener FFmpeg instalado en tu sistema
   - Para Ubuntu/Debian: `sudo apt install ffmpeg`
   - Para macOS (con Homebrew): `brew install ffmpeg`
   - Para Windows: [Descargar FFmpeg](https://ffmpeg.org/download.html)

4. En caso de utilizar WhisperX.

 La instalaci贸n suele dar problemas, la propia pagina de [WhisperX](https://github.com/m-bain/whisperX) tiene un apartado de solucion de problemas que puedes consultar. 


 Si sigue dando problemas, una posible solucion para tarjetas NVIDIA en sistemas operativos Ubuntu/Debian es la siguiente: 

   - Se necesita tener instalado el paquete `nvidia-cuda-toolkit` para ello ejecuta:
   ```bash
      sudo apt update && sudo apt install -y nvidia-cuda-toolkit
   ```

   - Luego sigue la gu铆a de instalaci贸n de cuDNN para tu sistema operativo. Puedes encontrar las instrucciones en el sitio oficial de [NVIDIA](https://developer.nvidia.com/cuda-downloads).

   - Finalmente, hay que ejecutar:
   ```bash
      # A帽adir el repo de NVIDIA si no est谩
      sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/3bf863cc.pub
      sudo add-apt-repository "deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /"

      # Actualizar e instalar cuDNN
      sudo apt update
      sudo apt install libcudnn8 libcudnn8-dev libcudnn8-samples
   ```

## Uso

Para ejecutar el transcriptor de whisper con los valores predeterminados solo es necesario la url del stream:

```bash
python transcriptor-whisper.py --url "https://www.youtube.com/watch?v=STREAM_ID"
```

Por otro lado, si deseas utilizar WhisperX, puedes ejecutar el siguiente comando:

```bash
python transcriptor-whisper.py --url "https://www.youtube.com/watch?v=STREAM_ID" --token "YOUR_HG_KEY" 
```


Los argumentos disponibles son:
- `--url`: URL del stream de YouTube a transcribir
- `--token`: Token de Hugging Face necesario para utilizar la diarizaci贸n en WhisperX, para m谩s informaci贸n visita el repositorio de [WhisperX](https://github.com/m-bain/whisperX?tab=readme-ov-file#speaker-diarization)
- `--model`: Tama帽o del modelo Whisper a utilizar (tiny, base, small, medium, large), predeterminado es `small`
- `--language`: C贸digo de idioma para la transcripci贸n (ej: es, en, fr), predeterminado se detecta autom谩ticamente
- `--output`: Archivo de salida para guardar la transcripci贸n, predeterminado es `transcripcion.txt`
- `--chunk-size`: Tama帽o del fragmento de audio en segundos, predeterminado es `10`

### Terminaci贸n del programa

Para detener la transcripci贸n en cualquier momento, simplemente presiona **Ctrl+C**. El programa finalizar谩 de manera controlada, asegur谩ndose de que todos los procesos terminen correctamente y que las transcripciones se guarden.

## Comentario sobre el proyecto
La implementaci贸n del modelo de Whisper es bastante sencilla, ya que se basa en la librer铆a `openai-whisper` y no requiere de una configuraci贸n compleja. Adem谩s, el procesamiento se realiza en memoria RAM, lo que permite una transcripci贸n r谩pida y eficiente. Se recomienda utilizar este script.

La implementaci贸n de WhisperX es m谩s complicada debido a la necesidad de manejar archivos temporales y la detecci贸n de hablantes, lo que a帽ade un nivel adicional de complejidad al proyecto. El rendimiento del modelo, o al menos de esta implementaci贸n, no es tan bueno como el de Whisper,dejando incluso bloques de audio sin procesar, por lo que se recomienda utilizarlo solo si se desea usar la diarizaci贸n.

## Estado del proyecto

 **En desarrollo** - Este proyecto acaba de iniciar y est谩 en proceso de implementaci贸n. A煤n no est谩 listo para uso en producci贸n.
